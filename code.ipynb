{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from fancyimpute import KNN\n",
    "plt.rcParams['font.family'] = ['sans-serif']\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
    "                              GradientBoostingClassifier, ExtraTreesClassifier)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看数据字段及类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/比赛训练集.csv', encoding='gbk')\n",
    "test_df = pd.read_csv('data/比赛测试集.csv', encoding='gbk')\n",
    "\n",
    "print(train_df.shape, test_df.shape)\n",
    "print(train_df.dtypes, test_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "缺失值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_nan(train_df,test_df,method = None):\n",
    "    #口服耐糖量测试为-1，也应该为null\n",
    "    train_df['口服耐糖量测试'] = train_df['口服耐糖量测试'].replace(-1, np.nan)\n",
    "    test_df['口服耐糖量测试'] = test_df['口服耐糖量测试'].replace(-1, np.nan)\n",
    "\n",
    "    train_df['口服耐糖量测试'] = train_df['口服耐糖量测试'].replace(0, np.nan)\n",
    "    test_df['口服耐糖量测试'] = test_df['口服耐糖量测试'].replace(0, np.nan)\n",
    "    if method is not None:\n",
    "        train_df['胰岛素释放实验'] = train_df['胰岛素释放实验'].replace(0, np.nan)\n",
    "        test_df['胰岛素释放实验'] = test_df['胰岛素释放实验'].replace(0, np.nan)\n",
    "\n",
    "        train_df['肱三头肌皮褶厚度'] = train_df['肱三头肌皮褶厚度'].replace(0, np.nan)\n",
    "        test_df['肱三头肌皮褶厚度'] = test_df['肱三头肌皮褶厚度'].replace(0, np.nan)\n",
    "\n",
    "    train_df['体重指数'] = train_df['体重指数'].replace(0, np.nan)\n",
    "    test_df['体重指数'] = test_df['体重指数'].replace(0, np.nan)\n",
    "    \n",
    "        # 训练集缺失值情况\n",
    "    print(train_df.isnull().mean(0))\n",
    "    # 训练集缺失值情况\n",
    "    print(test_df.isnull().mean(0))\n",
    "\n",
    "    \n",
    "    \n",
    "    #填充缺失值处理\n",
    "    #下列三个字段比例较低，可以直接填充\n",
    "    train_df['舒张压'].fillna(89, inplace=True)\n",
    "    test_df['舒张压'].fillna(89, inplace=True)\n",
    "\n",
    "    train_df['口服耐糖量测试'].fillna(6,inplace = True)\n",
    "    test_df['口服耐糖量测试'].fillna(6,inplace = True)\n",
    "\n",
    "    train_df['体重指数'].fillna(38,inplace = True)\n",
    "    test_df['体重指数'].fillna(38,inplace = True)\n",
    "\n",
    "\n",
    "    #胰岛素释放实验\t肱三头肌皮褶厚度    字段缺失比例较高，试试统计填充（多元线性回归）\n",
    "    all_df = pd.concat([train_df,test_df])\n",
    "    all_df.drop(['患有糖尿病标识'],axis=1,inplace=True)\n",
    "    all_df.dropna(inplace=True)\n",
    "    if method == 'lg':\n",
    "        lg_g3 = LinearRegression()\n",
    "        lg_yd = LinearRegression()\n",
    "        lg_features = [f for f in all_df.columns if f not in ['编号','肱三头肌皮褶厚度','胰岛素释放实验']]\n",
    "\n",
    "        lg_g3.fit(all_df[lg_features],all_df['肱三头肌皮褶厚度'])\n",
    "        lg_yd.fit(all_df[lg_features],all_df['胰岛素释放实验'])\n",
    "\n",
    "        for index,bool in enumerate (train_df['胰岛素释放实验'].isnull()):\n",
    "            if  bool:\n",
    "                train_df.loc[index,'胰岛素释放实验']  = lg_yd.predict(np.array(train_df.loc[index,lg_features]).reshape(1, -1))\n",
    "                \n",
    "            \n",
    "        for index,bool in enumerate (train_df['肱三头肌皮褶厚度'].isnull()):\n",
    "            if  bool:\n",
    "                train_df.loc[index,'肱三头肌皮褶厚度']  = lg_g3.predict(np.array(train_df.loc[index,lg_features]).reshape(1, -1))\n",
    "                \n",
    "        for index,bool in enumerate (test_df['胰岛素释放实验'].isnull()):\n",
    "            if  bool:\n",
    "                test_df.loc[index,'胰岛素释放实验']  = lg_yd.predict(np.array(test_df.loc[index,lg_features]).reshape(1, -1))\n",
    "                \n",
    "            \n",
    "        for index,bool in enumerate (test_df['肱三头肌皮褶厚度'].isnull()):\n",
    "            if  bool:\n",
    "                test_df.loc[index,'肱三头肌皮褶厚度']  = lg_g3.predict(np.array(test_df.loc[index,lg_features]).reshape(1, -1))        \n",
    "    \n",
    "    #试试knn拟合\n",
    "    if method == 'knn':\n",
    "        train_df = pd.DataFrame(KNN(k=5).fit_transform(train_df),columns= train_df.columns)\n",
    "        test_df = pd.DataFrame(KNN(k=5).fit_transform(test_df),columns= test_df.columns)\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "    return train_df,test_df        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "字段类型分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算相关性\n",
    "train_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in train_df.columns:\n",
    "    if column == '编号':\n",
    "        continue\n",
    "    if column == '患有糖尿病标识':\n",
    "        continue\n",
    "    plt.figure()\n",
    "    for i in [0,1]:\n",
    "        train_df[column][train_df['患有糖尿病标识']==i].hist()\n",
    "    plt.title(\"{}\".format(column))    \n",
    "    plt.savefig(\"fig/{}.png\".format(column))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 逻辑回归尝试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/比赛训练集.csv', encoding='gbk')\n",
    "test_df = pd.read_csv('data/比赛测试集.csv', encoding='gbk')\n",
    "\n",
    "train_df,test_df = do_nan(train_df,test_df)\n",
    "\n",
    "#划分训练集、验证集\n",
    "features = [f for f in train_df.columns if f not in ['编号','出生年份','患有糖尿病标识']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_df[features],train_df['患有糖尿病标识'],test_size=0.2, random_state=2022)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集表现\n",
    "l1_train_predict = []\n",
    "l2_train_predict = []\n",
    "\n",
    "# 测试集表现\n",
    "l1_test_predict = []\n",
    "l2_test_predict = []\n",
    "\n",
    "for c in np.linspace(0.01, 5, 50) :\n",
    "    lr_l1 = make_pipeline(MinMaxScaler(),\n",
    "    LogisticRegression(penalty=\"l1\", C=c, solver=\"liblinear\", max_iter=2000))\n",
    "    lr_l2 = make_pipeline(MinMaxScaler(),\n",
    "    LogisticRegression(penalty=\"l2\", C=c, solver=\"liblinear\", max_iter=2000))\n",
    "    \n",
    "    # 训练模型，记录L1正则化模型在训练集测试集上的表现\n",
    "    lr_l1.fit(x_train, y_train)\n",
    "    l1_train_predict.append(accuracy_score(lr_l1.predict(x_train), y_train))\n",
    "    l1_test_predict.append(accuracy_score(lr_l1.predict(x_test), y_test))\n",
    "    \n",
    "    # 记录L2正则化模型的表现\n",
    "    lr_l2.fit(x_train, y_train)\n",
    "    l2_train_predict.append(accuracy_score(lr_l2.predict(x_train), y_train))\n",
    "    l2_test_predict.append(accuracy_score(lr_l2.predict(x_test), y_test))\n",
    "    \n",
    "data = [l1_train_predict, l2_train_predict, l1_test_predict, l2_test_predict]\n",
    "label = ['l1_train', 'l2_train', 'l1_test', \"l2_test\"]\n",
    "color = ['red', 'green', 'orange', 'blue']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(4) :\n",
    "    plt.plot(np.linspace(0.01, 5, 50), data[i], label=label[i], color=color[i])\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in np.linspace(0.01, 2, 50):\n",
    "    best_model = make_pipeline(MinMaxScaler(),\n",
    "    LogisticRegression(penalty=\"l2\", C=0.614, solver=\"liblinear\", max_iter=2000))\n",
    "    best_model.fit(x_train,y_train)\n",
    "    acc = accuracy_score(best_model.predict(x_test),y_test)\n",
    "    print(c,acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于最优模型进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#取出最优参数，进行训练、预测\n",
    "best_model = make_pipeline(\n",
    "    MinMaxScaler(),\n",
    "    LogisticRegression(penalty=\"l2\", C=0.614, solver=\"liblinear\", max_iter=2000)\n",
    ")\n",
    "\n",
    "best_model.fit(train_df[features],train_df['患有糖尿病标识'])\n",
    "\n",
    "test_df['label'] = best_model.predict(test_df[features])\n",
    "test_df.rename({'编号': 'uuid'}, axis=1)[['uuid', 'label']].to_csv('submit.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征工程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "统计每个性别对应的体重指数、舒张压的平均值，并构建新特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_feature(train_df,test_df,sex, family):\n",
    "    if sex :\n",
    "        df_sex = train_df[['体重指数','舒张压']].groupby(train_df['性别']).mean()\n",
    "\n",
    "        train_df['体重指数_diff'] = [train_df.loc[i,'体重指数'] - df_sex.loc[train_df.loc[i,'性别'],'体重指数'] for i in range(len(train_df))]\n",
    "        train_df['舒张压_diff'] = [train_df.loc[i,'舒张压'] - df_sex.loc[train_df.loc[i,'性别'],'舒张压'] for i in range(len(train_df))]\n",
    "        \n",
    "        test_df['体重指数_diff'] = [test_df.loc[i,'体重指数'] - df_sex.loc[test_df.loc[i,'性别'],'体重指数'] for i in range(len(test_df))]\n",
    "        test_df['舒张压_diff'] = [test_df.loc[i,'舒张压'] - df_sex.loc[test_df.loc[i,'性别'],'舒张压'] for i in range(len(test_df))]\n",
    "    \n",
    "    if family :\n",
    "        df_family = train_df[['口服耐糖量测试','胰岛素释放实验']].groupby(train_df['糖尿病家族史']).mean()\n",
    "\n",
    "        for column in ['口服耐糖量测试','胰岛素释放实验']:\n",
    "            train_df[column +'_diff'] = [train_df.loc[i,column] - df_family.loc[train_df.loc[i,'糖尿病家族史'],column] for i in range(len(train_df))]\n",
    "            test_df[column +'_diff'] = [test_df.loc[i,column] - df_family.loc[test_df.loc[i,'糖尿病家族史'],column] for i in range(len(test_df))]\n",
    "            \n",
    "            \n",
    "    train_df['体重指数_round'] = train_df['体重指数'] // 10\n",
    "    test_df['体重指数_round'] = train_df['体重指数'] // 10\n",
    "\n",
    "\n",
    "    train_df['糖尿病家族史'] = train_df['糖尿病家族史'].astype('category')\n",
    "    test_df['糖尿病家族史'] = train_df['糖尿病家族史'].astype('category')\n",
    "\n",
    "    train_df['性别'] = train_df['性别'].astype('category')\n",
    "    test_df['性别'] = train_df['性别'].astype('category')\n",
    "\n",
    "    #将糖尿病家族史转换为类别变量\n",
    "    dict_糖尿病家族史 = {\n",
    "        '无记录': 0,\n",
    "        '叔叔或姑姑有一方患有糖尿病': 1,\n",
    "        '叔叔或者姑姑有一方患有糖尿病': 1,\n",
    "        '父母有一方患有糖尿病': 2\n",
    "    }\n",
    "    train_df['糖尿病家族史'] = train_df['糖尿病家族史'].map(dict_糖尿病家族史)\n",
    "    test_df['糖尿病家族史'] = test_df['糖尿病家族史'].map(dict_糖尿病家族史)\n",
    "\n",
    "    #出生年份转换\n",
    "    train_df['年龄'] = 2022 - train_df['出生年份']\n",
    "    test_df['年龄'] = 2022 - test_df['出生年份']\n",
    "\n",
    "    \n",
    "    train_df['口服耐糖量测试_diff'] = train_df['口服耐糖量测试'] - train_df.groupby('糖尿病家族史').transform('mean')['口服耐糖量测试']\n",
    "    test_df['口服耐糖量测试_diff'] = test_df['口服耐糖量测试'] - test_df.groupby('糖尿病家族史').transform('mean')['口服耐糖量测试']\n",
    "    return train_df,test_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.groupby('糖尿病家族史').transform('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/比赛训练集.csv', encoding='gbk')\n",
    "test_df = pd.read_csv('data/比赛测试集.csv', encoding='gbk')\n",
    "train_df,test_df = do_nan(train_df,test_df)\n",
    "train_df,test_df = do_feature(train_df,test_df,True,False)\n",
    "\n",
    "#划分训练集、验证集\n",
    "features = [f for f in train_df.columns if f not in ['编号','出生年份','患有糖尿病标识']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_df[features],train_df['患有糖尿病标识'],test_size=0.2, random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集表现\n",
    "l1_train_predict = []\n",
    "l2_train_predict = []\n",
    "\n",
    "# 测试集表现\n",
    "l1_test_predict = []\n",
    "l2_test_predict = []\n",
    "\n",
    "for c in np.linspace(0.01, 5, 50) :\n",
    "    lr_l1 = make_pipeline(MinMaxScaler(),\n",
    "    LogisticRegression(penalty=\"l1\", C=c, solver=\"liblinear\", max_iter=2000))\n",
    "    lr_l2 = make_pipeline(MinMaxScaler(),\n",
    "    LogisticRegression(penalty=\"l2\", C=c, solver=\"liblinear\", max_iter=2000))\n",
    "    \n",
    "    # 训练模型，记录L1正则化模型在训练集测试集上的表现\n",
    "    lr_l1.fit(x_train, y_train)\n",
    "    l1_train_predict.append(accuracy_score(lr_l1.predict(x_train), y_train))\n",
    "    l1_test_predict.append(accuracy_score(lr_l1.predict(x_test), y_test))\n",
    "    \n",
    "    # 记录L2正则化模型的表现\n",
    "    lr_l2.fit(x_train, y_train)\n",
    "    l2_train_predict.append(accuracy_score(lr_l2.predict(x_train), y_train))\n",
    "    l2_test_predict.append(accuracy_score(lr_l2.predict(x_test), y_test))\n",
    "    \n",
    "data = [l1_train_predict, l2_train_predict, l1_test_predict, l2_test_predict]\n",
    "label = ['l1_train', 'l2_train', 'l1_test', \"l2_test\"]\n",
    "color = ['red', 'green', 'orange', 'blue']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(4) :\n",
    "    plt.plot(np.linspace(0.01, 5, 50), data[i], label=label[i], color=color[i])\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in np.linspace(0.01, 2, 100):\n",
    "    best_model = make_pipeline(MinMaxScaler(),\n",
    "    LogisticRegression(penalty=\"l2\", C=c, solver=\"liblinear\", max_iter=2000))\n",
    "    best_model.fit(x_train,y_train)\n",
    "    acc = accuracy_score(best_model.predict(x_test),y_test)\n",
    "    print(c,acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/比赛训练集.csv', encoding='gbk')\n",
    "test_df = pd.read_csv('data/比赛测试集.csv', encoding='gbk')\n",
    "train_df,test_df = do_nan(train_df,test_df)\n",
    "train_df,test_df = do_feature(train_df,test_df,True,False)\n",
    "\n",
    "#划分训练集、验证集\n",
    "features = [f for f in train_df.columns if f not in ['编号','出生年份','患有糖尿病标识']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_df[features],train_df['患有糖尿病标识'],test_size=0.2, random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建模型\n",
    "model = make_pipeline(\n",
    "    MinMaxScaler(),\n",
    "    DecisionTreeClassifier()\n",
    ")\n",
    "#拟合结果\n",
    "model.fit(x_train,y_train)\n",
    "#查看特征重要度\n",
    "for index, importance in enumerate(model.named_steps['decisiontreeclassifier'].feature_importances_):\n",
    "    print(index, importance)\n",
    "model.named_steps['decisiontreeclassifier'].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['体重指数','舒张压','口服耐糖量测试', '胰岛素释放实验','肱三头肌皮褶厚度',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(train_df[features],train_df['患有糖尿病标识'],test_size=0.2, random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集表现\n",
    "l1_train_predict = []\n",
    "l2_train_predict = []\n",
    "\n",
    "# 测试集表现\n",
    "l1_test_predict = []\n",
    "l2_test_predict = []\n",
    "\n",
    "for c in np.linspace(0.01, 5, 50) :\n",
    "    lr_l1 = make_pipeline(MinMaxScaler(),\n",
    "    LogisticRegression(penalty=\"l1\", C=c, solver=\"liblinear\", max_iter=2000))\n",
    "    lr_l2 = make_pipeline(MinMaxScaler(),\n",
    "    LogisticRegression(penalty=\"l2\", C=c, solver=\"liblinear\", max_iter=2000))\n",
    "    \n",
    "    # 训练模型，记录L1正则化模型在训练集测试集上的表现\n",
    "    lr_l1.fit(x_train, y_train)\n",
    "    l1_train_predict.append(accuracy_score(lr_l1.predict(x_train), y_train))\n",
    "    l1_test_predict.append(accuracy_score(lr_l1.predict(x_test), y_test))\n",
    "    \n",
    "    # 记录L2正则化模型的表现\n",
    "    lr_l2.fit(x_train, y_train)\n",
    "    l2_train_predict.append(accuracy_score(lr_l2.predict(x_train), y_train))\n",
    "    l2_test_predict.append(accuracy_score(lr_l2.predict(x_test), y_test))\n",
    "    \n",
    "data = [l1_train_predict, l2_train_predict, l1_test_predict, l2_test_predict]\n",
    "label = ['l1_train', 'l2_train', 'l1_test', \"l2_test\"]\n",
    "color = ['red', 'green', 'orange', 'blue']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(4) :\n",
    "    plt.plot(np.linspace(0.01, 5, 50), data[i], label=label[i], color=color[i])\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in np.linspace(0.01, 2, 100):\n",
    "    best_model = make_pipeline(MinMaxScaler(),\n",
    "    LogisticRegression(penalty=\"l2\", C=c, solver=\"liblinear\", max_iter=2000))\n",
    "    best_model.fit(x_train,y_train)\n",
    "    acc = accuracy_score(best_model.predict(x_test),y_test)\n",
    "    print(c,acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 高阶树模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/比赛训练集.csv', encoding='gbk')\n",
    "test_df = pd.read_csv('data/比赛测试集.csv', encoding='gbk')\n",
    "train_df,test_df = do_nan(train_df,test_df)\n",
    "train_df,test_df = do_feature(train_df,test_df,False,False)\n",
    "\n",
    "#划分训练集、验证集\n",
    "features = [f for f in train_df.columns if f not in ['编号','出生年份','患有糖尿病标识']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_df[features],train_df['患有糖尿病标识'],test_size=0.2, random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建模型\n",
    "clf = lgb.LGBMClassifier(\n",
    "    max_depth=3, \n",
    "    n_estimators=4000, \n",
    "    n_jobs=-1, \n",
    "    verbose=-1,\n",
    "    verbosity=-1,\n",
    "    learning_rate=0.1,\n",
    ")\n",
    "\n",
    "#模型训练\n",
    "clf.fit(x_train,y_train)\n",
    "\n",
    "print(accuracy_score(y_test,clf.predict(x_test)))\n",
    "\n",
    "test_df['label'] = clf.predict(test_df[features])\n",
    "test_df.rename({'编号': 'uuid'}, axis=1)[['uuid', 'label']].to_csv('submit.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第一步：确定残差树的数目\n",
    "\n",
    "#给定一些初始的参数\n",
    "params = {    \n",
    "          'boosting_type': 'gbdt',\n",
    "          'objective': 'binary',\n",
    "          'metrics': 'binary_logloss',\n",
    "          'nthread':4,\n",
    "          'learning_rate':0.1,\n",
    "          'num_leaves':30, \n",
    "          'max_depth': 5,   \n",
    "          'subsample': 0.8, \n",
    "          'colsample_bytree': 0.8, \n",
    "    }\n",
    "#训练集\n",
    "data_train = lgb.Dataset(x_train, y_train)\n",
    "\n",
    "cv_results = lgb.cv(params, data_train, num_boost_round=1000, nfold=5, stratified=False, shuffle=True, metrics='binary_logloss',early_stopping_rounds=50,seed=0)\n",
    "print('best n_estimators:', len(cv_results['binary_logloss-mean']))\n",
    "print('best cv score:', pd.Series(cv_results['binary_logloss-mean']).min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第二步：确定max_depth 和num_leaves\n",
    "\n",
    "params_test1={'max_depth': range(3,8,1), 'num_leaves':range(5, 100, 5)}\n",
    "\n",
    "gsearch1 = GridSearchCV(estimator = lgb.LGBMClassifier(boosting_type='gbdt',objective='binary',metrics='binary_logloss',learning_rate=0.1, n_estimators=94, bagging_fraction = 0.8,feature_fraction = 0.8), \n",
    "                       param_grid = params_test1, scoring='accuracy',cv=5,n_jobs=-1)\n",
    "gsearch1.fit(x_train,y_train)\n",
    "gsearch1.best_params_, gsearch1.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第三步：确定min_data_in_leaf 、 max_bin\n",
    "\n",
    "params_test2={'max_bin': range(5,256,10), 'min_data_in_leaf':range(1,102,10)}\n",
    "gsearch2 = GridSearchCV(estimator = lgb.LGBMClassifier(boosting_type='gbdt',objective='binary',metrics='binary_logloss',learning_rate=0.1, n_estimators=94, max_depth=3, num_leaves=10,bagging_fraction = 0.8,feature_fraction = 0.8), \n",
    "                       param_grid = params_test2, scoring='accuracy',cv=5,n_jobs=-1)\n",
    "gsearch2.fit(x_train,y_train)\n",
    "gsearch2.best_params_, gsearch2.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第四步 确定feature_fraction、bagging_fraction、bagging_freq\n",
    "\n",
    "params_test3={'feature_fraction': [0.6,0.7,0.8,0.9,1.0],\n",
    "              'bagging_fraction': [0.6,0.7,0.8,0.9,1.0],\n",
    "              'bagging_freq': range(0,81,10)\n",
    "}\n",
    "              \n",
    "gsearch3 = GridSearchCV(estimator = lgb.LGBMClassifier(boosting_type='gbdt',objective='binary',metrics='binary_logloss',learning_rate=0.1, n_estimators=94, max_depth=3, num_leaves=10,max_bin=175,min_data_in_leaf=101), \n",
    "                       param_grid = params_test3, scoring='accuracy',cv=5,n_jobs=-1)\n",
    "gsearch3.fit(x_train,y_train)\n",
    "gsearch3.best_params_, gsearch3.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第五步 确定lambda_l1和lambda_l2\n",
    "params_test4={'lambda_l1': [1e-5,1e-3,1e-1,0.0,0.1,0.3,0.5,0.7,0.9,1.0],\n",
    "              'lambda_l2': [1e-5,1e-3,1e-1,0.0,0.1,0.3,0.5,0.7,0.9,1.0]\n",
    "}\n",
    "              \n",
    "gsearch4 = GridSearchCV(estimator = lgb.LGBMClassifier(boosting_type='gbdt',objective='binary',metrics='binary_logloss',learning_rate=0.1, n_estimators=94, max_depth=3, num_leaves=10,max_bin=175,min_data_in_leaf=101,bagging_fraction=0.6,bagging_freq= 0, feature_fraction= 0.8), \n",
    "                       param_grid = params_test4, scoring='accuracy',cv=5,n_jobs=-1)\n",
    "gsearch4.fit(x_train,y_train)\n",
    "gsearch4.best_params_, gsearch4.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第六步：确定 min_split_gain\n",
    "params_test5={'min_split_gain':[0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]}\n",
    "\n",
    "gsearch5 = GridSearchCV(estimator = lgb.LGBMClassifier(boosting_type='gbdt',objective='binary',metrics='binary_logloss',learning_rate=0.1, n_estimators=94, max_depth=3, num_leaves=10,max_bin=175,min_data_in_leaf=101,bagging_fraction=0.6,bagging_freq= 0, feature_fraction= 0.8,\n",
    "                                                       ambda_l1=0.7,lambda_l2=0.7), \n",
    "                       param_grid = params_test5, scoring='accuracy',cv=5,n_jobs=-1)\n",
    "gsearch5.fit(x_train,y_train)\n",
    "gsearch5.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第七步：降低学习率，增加迭代次数，验证模型\n",
    "model=lgb.LGBMClassifier(boosting_type='gbdt',objective='binary',metrics='binary_logloss',learning_rate=0.01, n_estimators=94, max_depth=3, num_leaves=10,max_bin=175,min_data_in_leaf=101,bagging_fraction=0.6,bagging_freq= 0, feature_fraction= 0.8,\n",
    "                                                       ambda_l1=0.7,lambda_l2=0.7,min_split_gain=0.1,num_iterations =10000)\n",
    "model.fit(x_train,y_train)\n",
    "y_pre=model.predict(x_test)\n",
    "print(\"acc:\",accuracy_score(y_test,y_pre))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_df[features],train_df['患有糖尿病标识'])\n",
    "test_df['label'] = model.predict(test_df[features])\n",
    "test_df.rename({'编号': 'uuid'}, axis=1)[['uuid', 'label']].to_csv('submit.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多折训练与集成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多折cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/比赛训练集.csv', encoding='gbk')\n",
    "test_df = pd.read_csv('data/比赛测试集.csv', encoding='gbk')\n",
    "train_df,test_df = do_nan(train_df,test_df)\n",
    "train_df,test_df = do_feature(train_df,test_df,False,False)\n",
    "\n",
    "#划分训练集、验证集\n",
    "features = [f for f in train_df.columns if f not in ['编号','出生年份','患有糖尿病标识']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_df[features],train_df['患有糖尿病标识'],test_size=0.2, random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型交叉验证\n",
    "def run_model_cv(model, kf, X_tr, y, X_te, cate_col=None):\n",
    "    train_pred = np.zeros( (len(X_tr), len(np.unique(y))) )\n",
    "    test_pred = np.zeros( (len(X_te), len(np.unique(y))) )\n",
    "    cv_clf = []\n",
    "    for tr_idx, val_idx in kf.split(X_tr, y):\n",
    "        x_tr = X_tr.iloc[tr_idx]; y_tr = y.iloc[tr_idx]\n",
    "\n",
    "        x_val = X_tr.iloc[val_idx]; y_val = y.iloc[val_idx]\n",
    "\n",
    "        call_back = [\n",
    "            lgb.early_stopping(50),\n",
    "        ]\n",
    "        eval_set = [(x_val, y_val)]\n",
    "        model.fit(x_tr, y_tr, eval_set=eval_set, callbacks=call_back, verbose=-1)\n",
    "\n",
    "        cv_clf.append(model)\n",
    "\n",
    "        train_pred[val_idx] = model.predict_proba(x_val)\n",
    "        test_pred += model.predict_proba(X_te)\n",
    "        \n",
    "\n",
    "    test_pred /= kf.n_splits\n",
    "    return train_pred, test_pred, cv_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义模型\n",
    "clf = lgb.LGBMClassifier(boosting_type='gbdt',objective='binary',metrics='binary_logloss',learning_rate=0.01, \n",
    "                         n_estimators=94, max_depth=3, num_leaves=10,max_bin=175,min_data_in_leaf=101,\n",
    "                         bagging_fraction=0.6,bagging_freq= 0, feature_fraction= 0.8,lambda_l1=0.7,lambda_l2=0.7,\n",
    "                         min_split_gain=0.1,num_iterations =5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred, test_pred, cv_clf = run_model_cv(\n",
    "    clf, KFold(n_splits=4),\n",
    "    x_train,\n",
    "    y_train,\n",
    "    x_test)\n",
    "\n",
    "test_pred_1 = [ i.argmax() for i in test_pred]\n",
    "accuracy_score(test_pred_1,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred, test_pred, cv_clf = run_model_cv(\n",
    "    clf, StratifiedKFold(n_splits=4),\n",
    "    x_train,\n",
    "    y_train,\n",
    "    x_test)\n",
    "\n",
    "test_pred_1 = [i.argmax() for i in test_pred]\n",
    "\n",
    "accuracy_score(test_pred_1,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred, test_pred, cv_clf = run_model_cv(\n",
    "    clf, StratifiedKFold(n_splits=5),\n",
    "    train_df[features],\n",
    "    train_df['患有糖尿病标识'],\n",
    "    test_df[features])\n",
    "\n",
    "test_pred_1 = [i.argmax() for i in test_pred]\n",
    "test_df['label'] = test_pred_1\n",
    "test_df.rename({'编号': 'uuid'}, axis=1)[['uuid', 'label']].to_csv('submit.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "编号          0.000000\n",
      "性别          0.000000\n",
      "出生年份        0.000000\n",
      "体重指数        0.001578\n",
      "糖尿病家族史      0.000000\n",
      "舒张压         0.048718\n",
      "口服耐糖量测试     0.049704\n",
      "胰岛素释放实验     0.000000\n",
      "肱三头肌皮褶厚度    0.000000\n",
      "患有糖尿病标识     0.000000\n",
      "dtype: float64\n",
      "编号          0.000\n",
      "性别          0.000\n",
      "出生年份        0.000\n",
      "体重指数        0.002\n",
      "糖尿病家族史      0.000\n",
      "舒张压         0.049\n",
      "口服耐糖量测试     0.018\n",
      "胰岛素释放实验     0.000\n",
      "肱三头肌皮褶厚度    0.000\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-da8a2013b959>:44: FutureWarning: Dropping invalid columns in DataFrameGroupBy.transform is deprecated. In a future version, a TypeError will be raised. Before calling .transform, select only columns which should be valid for the function.\n",
      "  train_df['口服耐糖量测试_diff'] = train_df['口服耐糖量测试'] - train_df.groupby('糖尿病家族史').transform('mean')['口服耐糖量测试']\n",
      "<ipython-input-6-da8a2013b959>:45: FutureWarning: Dropping invalid columns in DataFrameGroupBy.transform is deprecated. In a future version, a TypeError will be raised. Before calling .transform, select only columns which should be valid for the function.\n",
      "  test_df['口服耐糖量测试_diff'] = test_df['口服耐糖量测试'] - test_df.groupby('糖尿病家族史').transform('mean')['口服耐糖量测试']\n"
     ]
    }
   ],
   "source": [
    "#使用random forest、extratrees、adaboost、gradientboosting、svm作为第一层分类器\n",
    "#第二层防止过拟合，用lr\n",
    "\n",
    "train_df = pd.read_csv('data/比赛训练集.csv', encoding='gbk')\n",
    "test_df = pd.read_csv('data/比赛测试集.csv', encoding='gbk')\n",
    "train_df,test_df = do_nan(train_df,test_df)\n",
    "train_df,test_df = do_feature(train_df,test_df,False,False)\n",
    "\n",
    "#划分训练集、验证集\n",
    "features = [f for f in train_df.columns if f not in ['编号','出生年份','患有糖尿病标识']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_df[features],train_df['患有糖尿病标识'],test_size=0.2, random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to extend the Sklearn classifier\n",
    "class SklearnHelper(object):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)\n",
    "    \n",
    "    def fit(self,x,y):\n",
    "        return self.clf.fit(x,y)\n",
    "    \n",
    "    def feature_importances(self,x,y):\n",
    "        print(self.clf.fit(x,y).feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#底层模型交叉训练oof\n",
    "\n",
    "def get_oof(model, kf, X_tr, y, X_te, cate_col=None):\n",
    "    train_pred = np.zeros( (len(X_tr), )) \n",
    "    test_pred = np.zeros( (len(X_te), )) \n",
    "    cv_clf = []\n",
    "    for tr_idx, val_idx in kf.split(X_tr, y):\n",
    "        x_tr = X_tr.iloc[tr_idx]; y_tr = y.iloc[tr_idx]\n",
    "\n",
    "        x_val = X_tr.iloc[val_idx]; y_val = y.iloc[val_idx]\n",
    "\n",
    "        model.fit(x_tr, y_tr)\n",
    "\n",
    "        cv_clf.append(model)\n",
    "\n",
    "        train_pred[val_idx] = model.predict(x_val)\n",
    "        test_pred += model.predict(X_te)\n",
    "        \n",
    "\n",
    "    test_pred /= kf.n_splits\n",
    "    return train_pred, test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put in our parameters for said classifiers\n",
    "# Random Forest parameters\n",
    "rf_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 100,\n",
    "     'warm_start': True, \n",
    "     #'max_features': 0.2,\n",
    "    'max_depth': 3,\n",
    "    'min_samples_leaf': 4,\n",
    "    'max_features' : 'sqrt',\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# Extra Trees Parameters\n",
    "et_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators':150,\n",
    "    #'max_features': 0.5,\n",
    "    'max_depth': 6,\n",
    "    'min_samples_leaf': 4,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# AdaBoost parameters\n",
    "ada_params = {\n",
    "    'n_estimators': 150,\n",
    "    'learning_rate' : 0.25\n",
    "}\n",
    "\n",
    "# Gradient Boosting parameters\n",
    "gb_params = {\n",
    "    'n_estimators': 150,\n",
    "     #'max_features': 0.2,\n",
    "    'max_depth': 5,\n",
    "    'min_samples_leaf': 4,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# Support Vector Classifier parameters \n",
    "svc_params = {\n",
    "    'kernel' : 'linear',\n",
    "    'C' : 0.025\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 5 objects that represent our 5 models\n",
    "rf = SklearnHelper(clf=RandomForestClassifier, seed=2022, params=rf_params)\n",
    "et = SklearnHelper(clf=ExtraTreesClassifier, seed=2022, params=et_params)\n",
    "ada = SklearnHelper(clf=AdaBoostClassifier, seed=2022, params=ada_params)\n",
    "gb = SklearnHelper(clf=GradientBoostingClassifier, seed=2022, params=gb_params)\n",
    "svc = SklearnHelper(clf=SVC, seed=2022, params=svc_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is complete\n"
     ]
    }
   ],
   "source": [
    "# Create our OOF train and test predictions. These base results will be used as new features\n",
    "kf = KFold(n_splits=5)\n",
    "x_train = train_df[features]\n",
    "y_train = train_df['患有糖尿病标识']\n",
    "x_test = test_df[features]\n",
    "et_oof_train, et_oof_test = get_oof(et,kf, x_train, y_train, x_test) # Extra Trees\n",
    "rf_oof_train, rf_oof_test = get_oof(rf,kf,x_train, y_train, x_test) # Random Forest\n",
    "ada_oof_train, ada_oof_test = get_oof(ada,kf, x_train, y_train, x_test) # AdaBoost \n",
    "gb_oof_train, gb_oof_test = get_oof(gb,kf,x_train, y_train, x_test) # Gradient Boost\n",
    "svc_oof_train, svc_oof_test = get_oof(svc,kf,x_train, y_train, x_test) # Support Vector Classifier\n",
    "\n",
    "print(\"Training is complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第二层的训练及验证数据\n",
    "base_predictions_train = pd.DataFrame( {'RandomForest': rf_oof_train.ravel(),\n",
    "     'ExtraTrees': et_oof_train.ravel(),\n",
    "     'AdaBoost': ada_oof_train.ravel(),\n",
    "      'GradientBoost': gb_oof_train.ravel(),\n",
    "      'Svc':svc_oof_train.ravel()\n",
    "    })\n",
    "base_predictions_test = pd.DataFrame( {'RandomForest': rf_oof_test.ravel(),\n",
    "     'ExtraTrees': et_oof_test.ravel(),\n",
    "     'AdaBoost': ada_oof_test.ravel(),\n",
    "      'GradientBoost': gb_oof_test.ravel(),\n",
    "      'Svc':svc_oof_test.ravel()\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=101, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=101\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n"
     ]
    }
   ],
   "source": [
    "clf = lgb.LGBMClassifier(boosting_type='gbdt',objective='binary',metrics='binary_logloss',learning_rate=0.1, \n",
    "                         n_estimators=94, max_depth=3, num_leaves=10,max_bin=175,min_data_in_leaf=101,\n",
    "                         bagging_fraction=0.6,bagging_freq= 0, feature_fraction= 0.8,lambda_l1=0.7,lambda_l2=0.7,\n",
    "                         min_split_gain=0.1,num_iterations =5000)\n",
    "clf.fit(base_predictions_train,y_train)\n",
    "# accuracy_score(clf.predict(base_predictions_test),y_test)\n",
    "test_df['label'] = clf.predict(base_predictions_test)\n",
    "test_df.rename({'编号': 'uuid'}, axis=1)[['uuid', 'label']].to_csv('submit.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52634da84371cba311ea128a5ea7cdc41ff074b781779e754b270ff9f8153cee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
